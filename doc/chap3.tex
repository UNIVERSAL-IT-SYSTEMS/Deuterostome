\chapter{THE  MACHINES}\label{chap:cluster}

D machines work in a group. The smallest group might include two D
machines, both running on your desktop. One serves as a terminal, the
other as the computational workhorse. You could extend this group to
several workhorses, which might run locally in your (multi-processor)
desktop or run in different physical hosts that are networked across
your lab. In a variant, your D machine serving as terminal might run
on your home computer and the other machines of the group on hosts in
your lab. You might also recruit a group of D machines whose physical
hosts are interconnected for high-speed communication to perform
strongly coupled parallel computations (a `cluster').

Three specializations of D machine let you build groups that suit your work:

\begin{enumerate}
\item the D Virtual Terminal (\dcomp{dvt})
\item the D Node (\dcomp{dnode})
\item the D Pawn (\dcomp{dpawn})
\end{enumerate}

\noindent The \dcomp{dvt} serves as a combination of text and graphical
terminal between you and one or many \dcomp[dnode]{dnodes} that you have
recruited to do computations for you.

A \dcomp{dnode} includes an extended set of mathematical operators for
solving numerical problems (the set can be augmented by extrinsic
operators). A \dcomp{dnode} can use all processors of its host for
multi-threaded computations.

A \dcomp{dnode} itself can create a set of \dcomp[dpawn]{dpawns} for solving
large numerical problems in parallel on a cluster of hosts (and,
automatically, all processors of each host).

The \dcomp{dvt} and \dcomp[dnode]{dnodes}, and \dcomp[dnode]{dnodes}
among themselves, communicate point-to-point through a bi-directional
stream protocol that runs on tcp/ip. A \dcomp{dnode} and its
\dcomp[dpawn]{dpawns} communicate through the Multiple Message
Protocol (mpi), which usually runs on tcp/ip. The \emph{mpi} allows a
\dcomp{dnode} to control a cluster of \dcomp[dpawn]{dpawns} using
broadcasted messages.

Parallel computations in \dcomp[dpawn]{dpawns} are supported by PETSc
(`Portable, Extensible Toolkit for Scientific computation'). PETSc
includes a large body of solvers for linear algebra problems. PETSc
works on vectors and matrices that are stored across a machine cluster
rather than in one machine. Work on different chunks of the vectors
and matrices is divided amongst the different members of the cluster,
so that much of the work can be done in parallel.

To do as much work as needed in parallel, not only must the parts
directly supported by PETSc be done in parallel but also
time-consuming work specific for the problem (`filling the
matrix'). To allow you to do such specific work in parallel, the
\dcomp{dpawn} machine is laid out as a general purpose D machine
(including all computational means of a \dcomp{dnode}). The vectors
and matrices that PETSc operators expect to work on are created in
composite D objects, so that ordinary D operators can access them as
well. These D objects are created in each \dcomp{dpawn} of the cluster
to hold exactly the chunks of the vectors and matrices that this
\dcomp{dpawn} is assigned to work on. These objects contain mapping
information locating the local objects in the global vectors and
matrices. You create the PETSc objects of each \dcomp{dpawn} by code
specific to this \dcomp{dpawn} (this way parcelling the global vectors
and matrices yourself rather than have PETSc operators assign the
parcels). The code to fill in these objects and to do computations on
them using PETSc can be the same for all \dcomp[dpawn]{dpawns}
provided you write the code for filling the parcels using the mapping
information contained in the PETSc objects.

All phases of operating the \dcomp{dpawn} cluster are supported by a
library of procedures that is loaded with the `startup' code of the
\dcomp{dnode}. The library very much makes the \dcomp{dnode} look as the
machine that solves the entire problem while the involvement of the
\dcomp{dpawn} cluster remains visible only in a small amount of
overhead.

\section{Overview of machine-specific operators}

The following table summarizes the \emph{operators} that are specific
for one or more varieties of D machine, or whose behaviors differ
among machines. Only actual operators are included. These specific
operators are complemented by machine-specific procedures (`operators
written in D') that the different D machines derive from their
specific \file{startup_xxx.d} files.

\begin{supertable}
  {>{\opfont}l*{3}{>{\sffamily}c}}
  {Operators for dvt, dnode and dpawn machines}
  {
    \label{table:ops}
    \tablefirsthead{
      operator & dvt & dnode & dpawn\\
      \hline\vspace{-0.5\baselineskip}\\
    }
    \tablehead{
      \multicolumn{4}{l}{\small\sl continued from previous page}\\
      \vspace{-0.5\baselineskip}\\
      operator & dvt & dnode & dpawn\\
      \hline\vspace{-0.5\baselineskip}\\
    }
    \tabletail{
      \\\vspace{-1.5\baselineskip}\\
      \hline%\\\vspace{-1.5\baselineskip}\\
      \multicolumn{4}{r}{\small\sl continued on next page}\\
    }
    \tablelasttail{}
  }
\op*{connect} & + & + & - \\
\op*{disconnect} & + & + & - \\
\op*{send} & + & + & - \\
\op*{sendsig} & + & + & - \\
\op*{rsendsig} & - & + & - \\
\op*{getsocket} & + & + & - \\
\op*{getmyname} & + & + & - \\
\op*{getmyfqdn} & + & + & - \\\\

\op*{Xwindows} & + & + & - \\
\op*{Xdisplayname} & + & + & - \\
\op*{screensize} & + & + & - \\
\op*{makewindow} & + & + & - \\
\op*{deletewindow} & + & + & - \\
\op*{mapwindow} & + & + & - \\
\op*{resizewindow} & + & + & - \\
\op*{Xsync} & + & + & - \\
\op*{mapcolor} & + & + & - \\
\op*{drawline} & + & + & - \\
\op*{drawsymbols} & + & + & - \\
\op*{fillrectangle} & + & + & - \\
\op*{drawtext} & + & + & - \\
\op*{makewindowtop} & + & + & - \\\\
\op*{Xauth} & + & + & - \\
\op*{Xauthrev} & + & + & - \\
\op*{Xauthgen} & + & + & - \\
\op*{Xauthset} & + & + & - \\
\op*{Xwindows_} & - & + & - \\
\op*{Xconnect} & - & + & - \\
\op*{Xdisconnect} & - & + & - \\\\

\op*{nextevent} & + & - & - \\
\op*{aborted} & + & - & - \\
\op*{getmyport} & - & + & - \\
\op*{setconsole} & - & + & - \\
\op*{console} & - & + & - \\
\op*{killsockets} & - & + & - \\
\op*{socketdead} & - & + & - \\\\
\op*{loadlib} & - & + & + \\
\op*{nextlib} & - & + & + \\
\op*{quit} & + & - & + \\
\op*{lock} & - & + & + \\
\op*{unlock} & - & + & + \\
\op*{serialize} & - & + & + \\
\op*{threads} & - & + & + \\
\op*{makethreads} & - & + & + \\
\op*{tostderr} & - & + & + \\
\op*{halt} & - & + & + \\
\op*{continue} & - & + & + \\
\op*{vmresize} & - & + & + \\
\op*{getplugindir} & - & + & + \\\\

\op*{matmul_blas} & - & + & + \\
\op*{decompLU_lp} & - & + & + \\
\op*{backsubLU_lp} & - & + & + \\
\op*{invertLU_lp} & - & + & + \\
\op*{norm2} & - & + & + \\
\op*{matvecmul_blas} & - & + & + \\
\op*{triangular_solve} & - & + & + \\
\op*{givens_blas} & - & + & + \\
\op*{rotate_blas} & - & + & + \\\\

\op*{rthreads} & - & + & - \\
\op*{makerthreads} & - & + & - \\
\op*{checkrthreads} & - & + & - \\
\op*{rsend} & - & + & + \\\\

\op*{mpiprobe} & - & - & +\\
\op*{mpiiprobe} & - & - & +\\
\op*{mpisend} & - & - & +\\
\op*{mpirecv} & - & - & +\\
\op*{mpibarrier} & - & - & +\\
\op*{mpibroadcast} & - & - & +\\
\op*{mpirank} & - & - & +\\
\op*{mpisize} & - & - & +\\
\op*{groupconsole} & - & - & +\\\\

\op*{petsc_vec_create} & - & - & + \\
\op*{petsc_vec_copy} & - & - & + \\
\op*{petsc_vec_copyto} & - & - & + \\
\op*{petsc_vec_copyfrom} & - & - & + \\
\op*{petsc_vec_syncto} & - & - & + \\
\op*{petsc_vec_syncfrom} & - & - & + \\
\op*{petsc_vec_max} & - & - & + \\
\op*{petsc_vec_min} & - & - & + \\
\op*{petsc_vec_destroy} & - & - & + \\
\op*{petsc_mat_create} & - & - & + \\
\op*{petsc_mat_copy} & - & - & + \\
\op*{petsc_mat_copyto} & - & - & + \\
\op*{petsc_mat_copyfrom} & - & - & + \\
\op*{petsc_mat_syncto} & - & - & + \\
\op*{petsc_mat_syncfrom} & - & - & + \\
\op*{petsc_mat_destroy} & - & - & + \\
\op*{petsc_mat_dup} & - & - & + \\
\op*{petsc_mat_vecmul} & - & - & + \\
\op*{petsc_ksp_create} & - & - & + \\
\op*{petsc_ksp_destroy} & - & - & + \\
\op*{petsc_ksp_tol} & - & - & + \\
\op*{petsc_ksp_iterations} & - & - & + \\
\op*{petsc_ksp_solve} & - & - & + \\\\
\end{supertable}

\newpage


\section{The  D Virtual Terminal (\dcomp{dvt})}\label{sec:dvt}

You can start a \dcomp{dvt} process from a shell. Better support is
provided to a \dcomp{dvt} through a \dcomp{dvt}-configured
\dcomp{emacs} environment. In this environment, you can start a
\dcomp{dvt} by the \dcomp{emacs} command `esc-x dvt'. In both shell
environments, the \dcomp{dvt} inherits the shell as its console. You
therefore retain the editing capabilities of that shell when you work
at the console of the \dcomp{dvt}. In addition, the \dcomp{emacs}
environment provides many \dcomp{dvt} supporting functions through
bound keys. \dcomp{emacs} itself will operate through an X Window
system. The \dcomp{dvt} then will bring up an additional, graphical
user interface to itself consisting of three \dcomp{dvt} windows.

\subsection{The \dcomp{dvt} mill}

The test phase of the \dcomp{dvt} mill is implemented in D code
(cf. \ref{sec:mill}). This D code is loaded upon initialization when
the file \file{startup_dvt.d} is interpreted. The D code of the
outermost loop of the \dcomp{dvt} uses a dvt-specific operator,
\op{nextevent}, to determine, and react to, an event that requires the
attention of the machine. This operator delivers requests made by you
at the console of the \dcomp{dvt}, requests made by windows associated
with the \dcomp{dvt}, requests made from \dcomp[dnode]{dnodes} over
network connections, and an emergency signal. By this \emph{modus
  operandi} a \dcomp{dvt} will attend to new requests made to it only
after its current activity is completed. (This is an important
difference with regard to the behavior of a \dcomp{dnode} or
\dcomp{dpawn}). A \dcomp{dvt} is only interrupted upon sending it an
emergency signal: pressing `control-c' from \emph{bash} or `control-c
control-c' from the \dcomp{emacs} shell. Upon receiving this signal,
the \dcomp{dvt} will execute the \op{abort} operator. Likewise, when
an error is discovered in a \dcomp{dvt} activity itself, \op{abort} is
executed after displaying an error message.

If you make the \dcomp{dvt} perform major services (e.g., automate the
coordination of a job involving many \dcomp[dnode]{dnodes}), you must
organize your D code such that it can be executed in short bursts of
mill cycles rather than, in the worst case, in an endless loop that
prevents the outermost loop of the \dcomp{dvt} from attending to
external events through \op{nextevent}. If your \dcomp{dvt} code being
tested turns out such an obstinate customer, use the emergency signal
from the keyboard to restore \dcomp{dvt} responsiveness.

The operation of the \dcomp{dvt} mill ceases when the operator
\op{quit} is executed; this terminates the Linux process of the
\dcomp{dvt}.

Whenever a component of the \dcomp{dvt} detects an error condition, it
initiates a consistent error response: a string (revealing the
instance of discovery, like the operator name) and a numeral (coding
for the type of the error) are pushed on the operand stack, and the
`error' is executed. The operator \op{error} uses the string and
numeral on the operand stack to formulate a console error message;
after showing this message, \op{abort} is executed. This drops all
stacks and resumes execution of the outermost loop of the \dcomp{dvt}.



\subsection{The \dcomp{dvt} operators}\label{ssec:dvtops}

The operator set of the \dcomp{dvt} includes operators that either are
unique to the \dcomp{dvt} or are implemented there in a unique
way. Many of these `operators' actually are D procedures defined in
the file \file{startup_dvt.d}.

\begin{ops}
  stringbuf                           & nextevent    & eventparams...     \\
  active-obj                          & aborted      & --                 \\
  instance-string error-num           & error        & --                 \\
  instance-string error-num stringbuf & errormessage & message\_substring \\
--                                    & quit         & --                 \\
\end{ops}

\op{nextevent} takes a string buffer as operand and blocks
until an event requiring \dcomp{dvt} attention occurs. Several kinds of
event are detected and cause \op{nextevent} to push an active name
on the execution stack. These names and their significance are:

\begin{tabular}{OR}
  \proc*{consoleline} & `a phrase is available from the console keyboard' \\
  \proc*{nodemessage} & `a message has been sent from a \dcomp{dnode}'    \\
  \proc*{windowsize}  & `request to change the size of an X window'       \\
  \proc*{drawwindow}  & `request to (re)draw an X window'                 \\
  \proc*{mouseclick}  & `a mouse click into an X window has occurred'     \\\\
\end{tabular}

Additional information relevant for the event is communicated by
\op{nextevent} as follows:

\begin{description}
\item[\proc*{consoleline}] The keyboard phrase is returned in a
  substring of the string buffer operand
\item[\proc{nodemessage}] Dependent on the form of the message used in the
  \op{send} operator executed in the \dcomp{dnode}, a \op{save}
  operation is performed, and/or the root object of a received object
  tree is pushed on the operand stack. In all usages of \op{send},
  the received message string (substring of the string buffer) is
  pushed on the operand stack.
\end{description}

\noindent If the event originates from activity in an X window, the
dictionary associated with the window name is pushed on the dictionary
stack; this dictionary must be defined by you in \op{userdict} and be
associated there with a properly formed name: the letter `w' followed
by digits specifying the window\# (see \ref{ssec:windows}). The
dictionary must associate \proc{windowsize}, \proc{drawwindow}, and
\proc{mouseclick} with window-specific procedures. These procedures
receive their operands from \op{nextevent}:

\begin{description}
\item[\proc{windowsize}] The width and height of the window are pushed
  on the operand stack
\item[\proc{drawwindow}] No operands are passed
\item[\proc{mouseclick}] The abscissa, ordinate, and modifiers
  describing the mouse event are pushed on the operand
  stack. Modifiers are generated by keyboard keys simultaneously held
  down when the mouse button is clicked, or by using the 2nd to 5th
  button of a multi-button mouse. The encoding of the modifiers is the
  standard encoding of the X Window library (see file
  \file{startup_dvt.d} for assignments used in the \dcomp{dvt}).
\end{description}

Procedures named \proc{consoleline} and \proc{nodemessage} are defined
in \op{userdict} when the file \file{startup_dvt.d} is
interpreted. These procedures are part of the D code that implements
the behavior of the \dcomp{dvt} that we describe in this section.

\op{aborted} marks the current top object of the execution stack as
the object to which the stack is dropped when \op{abort} is
executed. Typically there is only one \op{aborted} context in a
\dcomp{dvt}. \op{error} is automatically invoked when a \dcomp{dvt}
operator discovers an error condition. \op{error} expects two operands
indicating the instance and cause of the error condition on the
operand stack. It assembles a message string from this information
(decoding the error number into a text message), prints the error
message on the console screen, and forces the execution of
\op{abort}. \op{errormessage} also composes an error message; it
returns the message as substring of the designated string buffer and
resumes normal execution.

\op{quit} terminates the \dcomp{dvt} process.

\subsubsection{Supervising of \dcomp[dnode]{dnodes}}

When a \dcomp{dvt} hooks up over a network with \dcomp[dnode]{dnodes}, it
serves as the console of these D machines. The \dcomp{dvt} provides a
mechanism to switch the console among the various D machines that are
hooked up to it. Initially, the console targets the \dcomp{dvt}'s D
machine itself.

\begin{procs}
                               -- & h_   & -- \\
                               -- & hk_  & -- \\
          (hostname) port# group# & _c   & -- \\
(hostname) port# group# dim_array & _csu & -- \\
                               -- & c_   & -- \\
                            node# & _dc  & -- \\
                            node# & _dx  & -- \\
                            node# & kill & -- \\
                  node#-or-group# & _t   & -- \\
                            node# & _r   & -- \\
\end{procs}

\proc{h_} prints a help message summarizing all `operators' that are
provided to the \dcomp{dvt} via the \file{startup_dvt.d} file.

\proc{hk_} prints a help message summarizing all keys that have been
bound to \dcomp{dvt}-supporting \dcomp{emacs} functions when the
\dcomp{dvt} runs inside \dcomp{emacs}.

\proc{_c} opens a connection between the \dcomp{dvt} and the
\dcomp{dnode} described by the name of its host and the D machine port
where this \dcomp{dnode} is listening (this port number is assigned to
the \dcomp{dnode} when the \dcomp{dnode} is started from a shell (see
the section on \dcomp[dnode]{dnodes})). Port numbers are positive
integers including $0$. When the connection is established, the target
\dcomp{dnode} is instructed to use this \dcomp{dvt} as its console and
to send \emph{X Window} communications to the \emph{X Window} server
on the host of this \dcomp{dvt}. (There is a more fancy version of
this command that tells also the \dcomp{dnode} to color all its text
communications with the \dcomp{dvt} so that they appear as visually
distinct.) The connected \dcomp{dnode} is assigned a node number. Node
numbers are positive integers ($0$ is reserved for the \dcomp{dvt})
and are assigned and disassigned to \dcomp[dnode]{dnodes} as these are
connected and disconnected (thus node 3 may be unused, whereas node 4
may be in use). Connected \dcomp[dnode]{dnodes} can be grouped by
associating them with a group number (a negative integer). The
\dcomp{dvt} broadcasts console phrases to all \dcomp[dnode]{dnodes} of
a group when a group is selected as the current target.

\proc{_csu} includes the functions of \proc{_c} but also sets up the
storage capacities of the \dcomp{dnode} to the dimensions specified in
\emph{dim\_array} that has the entries: $<$l opdssize excssize
dictssize vmsize\_in\_MB userdictsize $>$ (`opdssize', for instance,
is the capacity, in objects, of the \dcomp[dnode]{dnode's} operand
stack). \emph{\_csu} also instructs the \dcomp{dnode} to read and
interpret the \file{startup_dnode.d} file, which defines a library of
procedures in the primed \dcomp{dnode}.

\proc{c_} prints on the \dcomp{dvt} console screen the node numbers of
the dvt (which is $0$), and of all currently connected
\dcomp[dnode]{dnodes} together with their host name, port number,
status (`ready' or `busy'), and group number.

\proc{_dc} disconnects the specified \dcomp{dnode} from this
\dcomp{dvt}. Note that you can connect, disconnect, and reconnect
\dcomp[dnode]{dnodes} as often as you wish without interfering with
ongoing activity in the \dcomp[dnode]{dnode's} D machine: the
\dcomp{dnode} can continue to execute D code that constitutes a long
job, independent of whether it is connected to a
\dcomp{dvt}. \proc{_dc} does not tell the node to close \emph{X
  Window} activity on the \dcomp{dvt} host. You can continue to
interact with the \dcomp{dnode} using these windows, even though the
\dcomp{dnode} is no longer connected to a \dcomp{dvt} on this host.

\proc{_dx} acts like \proc{_dc} but also instructs the \dcomp{dnode}
being disconnected from the \dcomp{dvt} to close all \emph{X Window}
activities with the \dcomp{dvt} host.

\proc{kill} acts like \proc{_dx}, and, in addition, tells the
\dcomp{dnode} being disconnected to resize its memory allocations to
those of a dormant \dcomp{dnode}. This terminates all ongoing activity
in that \dcomp{dnode}, except its listening to incoming connection
requests.

\proc{_t} selects a node or group of nodes as the target(s) for
subsequent console input. (again, node \#$0$ directs keyboard input to
the \dcomp{dvt} itself).

\proc{_r} forces the `ready` status of the node. When a \dcomp{dnode}
that is the currently selected target is given a console phrase to
execute, the status of this node is set to `busy`, and the console
phrase is delivered to the \dcomp{dnode} together with a request to
inform the \dcomp{dvt} when the activity started by this console
phrase has been completed (or stopped). When the \dcomp{dvt} receives
this completion message, it sets the status of the node to
`ready'. This mechanism ensures that activity initiated by a console
phrase delivered to a \dcomp{dnode} will be completed before you can
give another console phrase to the
\dcomp{dnode}. (\dcomp[dnode]{dnodes} interrupt their activity to
respond to requests made on their connections). If you try to give a
console phrase to a `busy' node, the \dcomp{dvt} will refuse (discard)
it and warn you by the console message ``Wait!''. You can override
this mechanism by prefixing your console phrase with a tag (see
below). Note that this mechanism belongs to the \dcomp{dvt} ---
\dcomp[dnode]{dnodes} are unaware of its existence.

Many of the \dcomp{dvt} operators described above can be invoked, in a
more convenient interface, by selecting from an \emph{X Window}
windows entitled \win{TheHorses} and \win{DVT Macros} (described later in
this section).

\subsection{Tagged console phrases}

Certain characters when appearing as the first character of a console
phrase direct the \dcomp{dvt} to treat the remainder of the console
phrase in some special way. The effect of the tag will also depend on
the currently selected target type, \dcomp{dvt}, \dcomp{dnode} or
\dcomp{dpawn}.

\begin{supertabular}{>{\bfseries}L>{\itshape}L>{\sffamily}p{0.75\textwidth}}
  No tag & dvt   & execute phrase as D code                      \\
         & dnode & transmit phrase as D code to the \dcomp{dnode}, 
                    observing the `ready/busy' rule              \\
         & dpawn & transmit phrase as D code to the \dcomp{dnode},
                    which then re-transmits phrase as D code to the
                    D pawn, observing `ready/busy' rule for both \\\\
  !      & dvt   & execute phrase as D code                      \\
         & dnode & transmit phrase as D code to the \dcomp{dnode}, 
                    disregarding  the `ready/busy` 
                    rule                                         \\
         & dpawn & goes directly to \dcomp{dnode}, as above; 
                   \dcomp{dpawn} selection ignored.              \\\\
  \$     & dvt   & submit phrase as Unix shell command to the 
                    host of the \dcomp{dvt}                      \\
         & dnode & transmit phrase and submit it as Unix shell 
                    command to the 
                    host of the \dcomp{dnode}, observing the 
                    `ready/busy' rule                            \\
         & dpawn & same as \dcomp{dnode}, but directed at
                    \dcomp{dpawn} instead.                       \\\\\relax
  #      & dvt   & execute phrase in the D machine of the \dcomp{dvt}, 
                    use results to build a Unix shell command, 
                    submit the shell command to 
                    the host of the \dcomp{dvt}                  \\
         & dnode & execute phrase in the D machine of the \dcomp{dvt}, 
                    use results to build a Unix shell command, 
                    submit the shell command to the host of the \dcomp{dnode}, 
                    observing the `ready/busy' rule              \\
         & dpawn & same as \dcomp{dnode}, but directed at
                   \dcomp{dpawn} instead.                        \\\\\relax
  @      & dvt   & execute phrase in the D machine of the \dcomp{dvt}, 
                    use results to build a Unix shell command, 
                    submit the shell command 
                    to the host of the \dcomp{dvt}               \\
         & dnode & transmit the phrase to the \dcomp{dnode} 
                    and execute it in the D machine 
                    of the \dcomp{dnode}; 
                    make the \dcomp{dnode} build a 
                    Unix shell command from the 
                    results, and submit it to the host 
                    of the \dcomp{dnode}, 
                    observing the `ready/busy' rule              \\
         & dpawn & same as \dcomp{dnode}, but directed at
                   \dcomp{dpawn} instead.                        \\\\\relax
  ^      & dvt   & execute phrase as D code                      \\
         & dnode & execute phrase as D code                      \\
         & dpawn & execute phrase as D code on the \dcomp{dnode}, 
                    disregarding \dcomp{dpawn} selection         \\\\
  \%     & dvt   & execute phrase as D code                      \\
         & dnode & execute phrase as D code on the \dcomp{dvt}, 
                    disregarding which \dcomp{dnode} 
                    owns the keyboard                            \\
         & dpawn & execute phrase as D code on the \dcomp{dvt},
                    disregarding which \dcomp{dnode}
                    owns the keyboard -- and any \dcomp{dpawn}
                    selection, of course
\end{supertabular}

The @ and \# tags have complex effects --- you will hardly use them
when typing console phrases (they rather are used in `macros' produced
by clicks into the \win{DVT Macros} window maintained by the \dcomp{dvt}
when it uses \emph{X Window}. The \textasciicircum{} and \% tags are
also rarely used directly; their primary use is for \win{DVT Macros}
commands that must be directed to the \dcomp{dvt} or a \dcomp{dnode},
bypassing temporarily any \win{TheHorses} or \win{ThePawns} selections.

\subsection{Key bindings supporting the \dcomp{dvt}}

When a \dcomp{dvt} is started through the \dcomp{emacs} command `esc-x
dvt', the following key bindings with \dcomp{dvt}-supporting
\dcomp{emacs} functions are created:

\begin{tabular}{>{\sffamily\bfseries}l>{\sffamily}l}
    f1 & execute the previous console phrase\\
    f2 & send `continue' to the dvt/dnode\\
    f3 & send `stop' to the dvt/dnode\\
    f4 & send `abort' to the dvt/dnode\\
    f5 & pop up \win{TheHorses} window\\
    f6 & pop up all dvt/dnode windows\\
    shift-f6 & iconify all dvt/dnode windows\\
    f7 & raise the dvt emacs frame\\
    f8 & start a local dnode\\
    control-h d & get this help\\
    control-! & ignore busy state when sending to dnodes\\
    control-1 & same as control-!\\
    control-c c & clear preceding text from emacs window\\
    control-c control-a & send phrase wrapped in `debug abort'\\
    control-$>$ & send output to log file\\
    control-c control-n & narrow dvt buffer\\
    control-c control-w & widen dvt buffer\\
\end{tabular}

If you wish to see also the names of the corresponding emacs Lisp
functions, use `control-h d'.

Another service provided by the \dcomp{emacs} environment is language
support for D. When you edit D code in a edit buffer or the shell
buffer you receive editing support (e.g. matching parentheses are
indicated). The different D objects are highlighted in color (you can
toggle this feature off or on using the standard \dcomp{emacs} command
`esc-x fontlockmode').

\subsection{The graphical user interface of the  \dcomp{dvt}}

When the \dcomp{dvt} process is running on a host that provides an
\emph{X Window} server, it will create and maintain three windows, two
of which are \dcomp{dvt}-specific and one of which is also implemented
by \dcomp[dnode]{dnodes}. The D code for operating these windows is
contained in the file \file{startup_dvt.d}, so that it is loaded when
the \dcomp{dvt} process is started up. The three windows are:

\begin{description}
\item[\win{TheHorses}] shows the list of D machines that currently
  form a cluster. The \dcomp{dvt} is listed at the top, followed by
  the connected \dcomp[dnode]{dnodes} (described as hostname:
  port\#). The background of each entry shows the status of the node:
  white for `ready', and green for `busy'. The currently selected
  target(s) for console input is (are) are highlighted by showing
  their name(s) in blue and boldface. You can select a D machine as
  target by a mouse click. You can select a group of
  \dcomp[dnode]{dnodes} as targets by control/clicking on one of the
  nodes of the group. Only one \dcomp{dnode} or group will be selected
  at a given time. You can force the \dcomp{dvt} to set a
  \dcomp{dnode} connection to the `ready' status by shift/clicking on
  it. If you have a multi-button mouse: shift/click and control/click
  are equivalent to clicking on buttons 2 or 3.

\item[\win{DVT Macros}] displays a list of command mnemonics. When you
  click on a mnemonic, a string is placed into the console screen. You
  can execute this string as a console phrase by moving the cursor
  over it and pressing `return' (function key `F1' combines both
  actions). Typically, you will have to click two mnemonics to produce
  a complete command, one designating a source and the other a
  destination object. The source and destination objects, in turn, are
  derived from objects selected in the third window, called
  \win{TheEye}. 

  \begin{nopb}
  For instance, you may: 
  \begin{enumerate}
  \item select a .tex file using \win{TheEye} by clicking on it
  \item click in \win{DVT Macros} on `tex' on the `PrintFrom' line
  \item click in \win{DVT Macros} on `pdf' on the `PrintTo' line
  \item press `F1'.
  \end{enumerate}
  This will compile the .tex file and submit it to a program for
  display and optional printing. The services of the \win{DVT Macros}
  are defined by shell scripts and by D code contained in
  \file{startup_dvt.d}.
  \end{nopb}

  Note that you can modify console phrases
  produced by \win{DVT Macros} by editing them prior to submitting
  them for execution: clicking mnemonics of \win{DVT Macros} simply
  provides templates for commands that are hard to remember. Such a
  command phrase is placed into the console buffer so that you can
  execute it (press `F1'), or execute it after some editing from your
  hand.

\item[\win{TheEye}] lets you view any object contained in the
  associated D machine, and any file system known to the host from
  which the \win{TheEye} originates. Thus \win{TheEye} is the
  universal browser of D machines. Both the \dcomp{dvt} and
  \dcomp[dnode]{dnodes} connected to a \dcomp{dvt} will create and
  maintain their own \win{TheEye} windows (with their owners
  identified in the window header). \win{TheEye} is operated through
  the mouse.

  \begin{itemize}
  \item The body of the window is divided into two pages. The left
    page shows permanent objects at the top followed by objects opened
    during use of \win{TheEye}. The right side lists the objects in
    the currently open object.

  \item A field along the bottom of each page lets you scroll to the
    beginning or end of the page, up and down by one page, or up and
    down by one line. Click on the respective symbols.

  \item Composite D objects are highlighted in both pages by
    backgrounds in different shades of green; simple D objects are
    displayed on a white background. File directories are listed on a
    purple background, and simple files on white background.

  \item The left page shows in two columns the class of D object in an
    intuitive notation, or `DIR' for file directories. The second
    column shows the name of the object.

  \item The right page shows in the left column the name of D objects
    and in the right column an intuitive description of the composite
    object or the value of a simple object. A filesystem is displayed
    in a single column of names, starting with directories (on a
    purple background) and followed by simple files. Each group of
    entries is alphabetically sorted.

  \item A field along the top of the two pages is used to display
    information on the object (of either page) that you click on.

  \item Control-clicking (or clicking the right mouse button) onto a
    composite D object or directory opens the contents of that object
    in the right page and appends the object to the left page (unless
    it already exists there). You can remove an item from the left
    page by shift-clicking on it.

  \item Clicking the middle mouse button (or pressing the `superkey'
    and the left mouse button) selects an item. You can select only
    one item on the left page but many items on the right
    page. Selected items are highlighted in boldface and red (left
    page) or blue (right page).
  \end{itemize}

  Selected items can be inquired by your D code from \win{TheEye}
  running from the same D machine using procedures that are loaded
  with the `startup' file into \emph{userdict}:

  \begin{procs}
    stringbuf index & faxLpage & stringbuf new_index                \\
    stringbuf index & faxRpage & stringbuf new_index                \\
    --              & getLpage & object true                        \\
                    &          & false                              \\
    --              & getRpage & [ D\_object\ldots ]                \\
                    &          & [ (path) [ (dir/filename)\ldots ]] \\
                    &          & [ ]                                \\
  \end{procs}

  \proc{faxLpage} or \proc{faxRpage} append to a byte array the string
  representation of a directory selected in the left page or of
  directories/files selected in the right page and update the buffer
  index to the position folowing the insertion. The string format is
  suitable for presenting arguments to shell commands. If nothing is
  selected or other types of object are selected, nothing is appended.

  \proc{getLpage} returns a D object selected in the left page, or a
  string containing the path of a selected directory, and true, or
  simply false if no object is selected. \proc{getRpage} returns a
  list, which is empty if no object of the right page is
  selected. Selected D objects are returned as the value of the
  list. For selected directories or files a path string followed by a
  list of directory/filename strings is returned.
\end{description}

\section{The D node (\dcomp{dnode})}\label{sec:dnode}

The \dcomp{dnode} is the specialization of D machine that provides you
with computational workhorses. A \dcomp{dnode} is brought up by a
shell command addressed to its host. The command is `dnode \#' where
`\#' is a numeral that defines a communication port at which this
`dnode' will listen for connection requests made via the network. (The
specified port number will be used as an offset into the range of
user-reserved ports, with no absolute warranty that your chosen port
is free -- in rare instances you may have to choose a different
port). The D machine of the \dcomp{dnode} is assigned minimal memory
resources at this time. More memory can be allocated when you take
control of the \dcomp{dnode} via the network.

A \dcomp{dnode} is alerted (from a state of dormancy that uses no CPU
cycles, or amidst the execution of D code) whenever a connection
request is made to it, when an established connection is the receiving
end of the \op{send} operator executed in another D machine, or when
an established \emph{X Window} connection requires attention. The code
that schedules reactions to such events is buried in the mill of the
\dcomp{dnode} (whereas in the \dcomp{dvt} these events are attended to
by code written in D).

The \dcomp{dnode} mill tests for external conditions at intervals no
greater than the time needed to go round 100 turns, which typically is
a very small amount of time on a human scale. When an event is
detected it is attended to, interrupting and suspending ongoing
execution of D code.  You can protect a D context against such
interruption by executing it using the \op{locked} operator. A
\dcomp{dvt} normally will pace the execution of your console phrases
so that the \dcomp[dnode]{dnodes} it supervises will not be
interrupted. X window events do not pace their demands made to the
\dcomp{dnode}, particularly when they arise from an impatient user. It
is therefore a good idea to protect X window responses of a
\dcomp{dnode} by \op{lock}. The interruption of other D code by X
window events is not a problem because X window response procedures
leave behind the same D machine state that existed when the interrupt
occured (please remember when you write your own).

The \dcomp{dnode} mill schedules D code in response to X window events
in the same way as the \dcomp{dvt} operator \op{nextevent} (see
\ref{ssec:dvtops}). Thus the same D code can be used in \dcomp{dvt}
and \dcomp{dnode} machines to service X windows. When a message is
received from another D machine (that uses \op{send}), the received
object is made active and pushed on the execution stack. If this
(composite) object is not a string, a \op{save} is executed before
the object is unfolded into the VM space (see also
\ref{ssec:network}).

A \dcomp{dnode} is terminated by killing its process from the Linux
shell that was used to bring it up. A \dcomp{dnode}, however, will
typically not be killed after a job: it rather is put into a dormant
state (using \op{vmresize}) from which it can be recruited by a
\dcomp{dvt} for new work. Thus \dcomp[dnode]{dnodes} are used like
servers.

Whenever the mill of the \dcomp{dnode} detects an error condition, it
initiates a consistent error response. Four objects are pushed on the
operand stack (from bottom to top): the host name of the
\dcomp{dnode}, the port\# of the \dcomp{dnode}, a string (revealing
the instance of discovery, like the operator name), and a numeral
(coding for the type of the error). The active name `error' is pushed
on the execution stack. `error' normally resolves to the operator
\op{error}. \op{error} formulates an error message from the four
objects pushed by the mill on the operand stack, sends the message to
the current console, and invokes the operator \op{halt}. \op{halt} has
two effects: (1) it pushes a copy of itself on the execution stack and
(2) it directs the mill to submit phrases entered to the console to
execution. Thus you can interact with the failed \dcomp{dnode}, e.g.,
inspect stack and object contents related to the error while the
context that produced the error is suspended. If you can fix the error
from the console, you may choose to execute \op{continue}, which drops
the execution stack below the topmost \op{halt} object and thus
resumes execution of the context suspended by that
\op{halt}. Alternatively, if you consider the problem fatal, you can
terminate the flawed context by executing \op{stop} (if you have set
up a capsule with \op{stopped}) or \op{abort}. \op{abort} drops all
stacks to their floors (which on the dictionary stack leaves only
\op{systemdict} and \op{userdict}). This cancels all activity in the
\dcomp{dnode}, and returns the machine to a state in which it will
respond to \dcomp{dnode} and X window connections.


\subsection{Operators for administrating  a \dcomp{dnode}}\label{ssec:opsdnode} 

\begin{ops}
long_array/null    & vmresize     & bool                  \\
--                 & halt         & --                    \\
--                 & continue     & --                    \\
--                 & stop         & --                    \\
--                 & abort        & --                    \\
active_obj         & lock         & ??                    \\ 
active_obj         & unlock       & ??                    \\
--                 & console      & consolesocket/null    \\
consolesocket/null & setconsole   & --                    \\
string             & toconsole    & --                    \\
string             & tostderr     & --                    \\
hostname port# sourcestr!
numerr             & error        & --                    \\
hostname port# sourcestr!
numerr strbuf      & errormessage & mesg_str              \\
--                 & getmyport    & port#                 \\
--                 & Xwindows_    & bool                  \\
(hostname:screen#) & Xconnect     & --                    \\
--                 & Xdisconnect  & --                    \\
num                & makethreads  & --                    \\ 
--                 & threads      & num                   \\ 
active_obj         & serialize    & --                    \\
--                 & getlibdir    & string                \\
(path) (filename)  & loadlib      & lib_dict              \\
--                 & hi           & (library description) \\
--                 & libnum       & num                   \\
null/lib_dict      & nextlib      & dict true             \\
                   &              & false                 \\
\end{ops}

The \dcomp{dnode} lets you resize the VM and stack dimensions
(\op{vmresize}). When given the \op*{null} object as operand,
\op{vmresize} establishes a tiny VM, renders the \dcomp{dnode}
dormant, and returns \op*{true}. When given the array of type long as
operand, \op{vmresize} establishes stack, VM, and \op{userdict}
dimensions as specified by the elements of the array, in the order:
operand stack size (in objects), dictionary stack size, execution
stack size, VM capacity (in MB), and userdict capacity (in
associations). \op{vmresize} indicates sucess/failure of the
attempted memory allocation in \emph{bool}. When used with the array
operand, \op{vmresize} also sets the startup and working file
directories back to the original working directory (from which the
\dcomp{dnode} has been started up); lastly, \op{vmresize} makes the
\dcomp{dnode} interpret the file \file{startup_dnode.d}.

\op{halt} suspends the execution of the object file currently held
on the execution stack, while accepting and executing keyboard phrases
from the console as well as any new objects placed on the execution
stack via the console (e.g., to investigate a condition that produced
execution of \op{halt}). The suspension is removed (and the halted
activity continued) by \op{continue}. \op{stop} or \op{abort}
also unblock the execution stack but drop the execution stack
according to the latest context established by \op{stopped} or to
the bottom of the stack (\op{abort} also clears operand and
dictionary stacks, excluding the permanent dictionaries).

The \dcomp{dnode} normally reacts to any message received from another
D machine within 100 turns of the mill. If a context is not to be
interrupted this way, execute this context by making it the operand of
\op{lock}. Lock contexts can be nested, including unlocked contexts by
calling \op{unlock} with an active object to be executed. Both
operators return whatever their operand returns, unchanged. Both are
also \op{stop}, \op{abort}, and \op{halt} safe (\op{halt}
automatically creates an unlocked context for itself).

Several operators allow a \dcomp{dnode} to organize its interactions
with the current console. \op{console} inquires the socket currently
subserving the console connection. It returns a socket-type
\op*{null} object when a console is connected. Otherwise, a plain
\op*{null} object is returned. \op{setconsole} when given the
object returned by \op{console} directs \op{toconsole} to the
connected console or to 'stderr' of the \dcomp{dnode}
host. \op{toconsole} sends the contents of its string operand to the
target chosen by \op{setconsole}. \op{tostderr} sends its string
operand always to `stderr' of the host.

Upon detecting an error the \dcomp{dnode} mill invokes the active name \emph{error}, which it provides with four operands: hostname (string), port number (where the \dcomp{dnode} is listening for connection requests, actually an offset used when the \dcomp{dnode} is started from a shell), a string describing the source of the error, and a numeral specifying the nature of the error (positive: D machine error; negative: extrinsic operator error) on the operand stack. \emph{error} is by defaults associated with an operator that composes an error message from this information (in red) and sends it to the current console (or `stderr' by default). \emph{error} executes \emph{halt} after the error information has been successfully decoded; otherwise it executes \emph{abort}. \emph{errormessage}, rather than sending the error message to the console and interrupting execution in the \dcomp{dnode}, simply places the message into a string buffer and returns the message string (excluding color accents) for use by \dcomp{dnode} code itself..

\emph{Xwindows\_} inquires whether X Window capabilities have been compiled into this \dcomp{dnode} when the \dcomp{dnode} was built (by contrast, the common operator \emph{Xwindows} inquires whether a connection to an X Window system has been established so that you can make windows). An X Window connection is made by \emph{Xconnect} and broken by \emph{Xdisconnect}. See \ref{ssec:windows} for a description of the protocols by which the \dcomp{dvt} and \dcomp{dnode} cooperate to connect up to X windows.

The standard mathematical operators described in Chapter \ref{chap:machine}, and their `old-style' extensions described in \ref{ssec:oldstyle}, can be executed using multiple threads (processors) available in the host Linux box. \emph{makethreads} creates the number of threads specified by the numeral operand (1 through a maximal number, which currently is 8). When a \dcomp{dnode} is started up or when it is reduced to the dormant state by \emph{vmresize}, it operates with a single thread. It is possible, though unlikely to be helpful, to have more threads than physical processors in a Linux box. If you wish to execute a context in a single thread although multiple threads currently exist, submit the context to \emph{serialize}. \emph{threads} inquires the current number of created threads. The `new-style' (BLAS- and LAPACK-based) extensions of mathematical operators use an intrinsically set number of threads (fixed when the \dcomp{dnode} program is built for the particular host).

In addition to the intrinsic operators, \dcomp[dnode]{dnodes} can make use of libraries of extrinsic operators (which typically support specific projects or experimental extensions of the D machine). \emph{getlibdir} inquires the directory path where libraries for the \dcomp{dnode} are stored (this path is established when the \dcomp{dnode} is started). \emph{loadlib} loads a library of operators; libraries are stored from the top of the VM downwards (competing for VM space with D objects, which are stored from bottom up) and returns the dictionary of the extrinsic operators contained in that library. \emph{loadlib} also merges the extrinsic operators of the library into \emph{systemdict} (with the exceptions of \emph{hi} and \emph{libnum}). You cannot load multiple copies of the same library. A library dictionary must include two obligatory operators with library-specific effects, \emph{hi} and \emph{libnum}. \emph{hi} returns a string specifying the library name and version. \emph{libnum} returns a dynamic index for this library (1,..., in the order of loading). You can inquire which libraries are currently loaded by \emph{nextlib}, which works similarly to \emph{nextobj}. Extrinsic operator libraries are not individually unloaded; they rather are altogether removed by \emph{vmresize}.


\subsection{More mathematical operators (old style)}\label{ssec:oldstyle}

These operators have been added to the D machine as ad hoc extensions. They fill demands made by specific applications and alleviate computational bottlenecks. The old style operators should be considered obsolete for most new work -- they have been or will be replaced by new-style versions that execute faster by better use of the hardware. These old-style operators describe two-dimensional arrays as lists of row arrays. New-style operators will consistently use different representations of multi-dimensional arrays.\\


\begin{tabular}{>{\sffamily}r>{\sffamily\bfseries}l>{\sffamily}l}
c a b & matmul & c\\
b a & mattranspose & b\\
c a b & matvecmul & c\\
array & integrateOH & array\\
array & integrateRS & array\\
y\_array dx\_array & integrateOHv\\
a b c r u & solvetridiag & u bool\\
bandlist bandrh main\_idx & solv\_bandmat & bool\\
a idx & decompLU  & d true\\
      &          & false\\
a idx b & backsubLU & b\\
a idx b & invertLU & b true\\
        &          & false\\
bandlist llist main\_idx idx & bandLU & bandlist llist main\_idx idx bool\\
bandlist llist main\_idx idx b & bandbs & b\\
array dir & complexFFT & array \\
array dir & realFFT & array\\
array dir & sineFFT & array\\\\
\end{tabular}

\index{Operators!matmul}
\index{Operators!mattranspose}
\index{Operators!matvecmul}
\index{Operators!integrateOH}
\index{Operators!integrateRS}
\index{Operators!integrateOHv}
\index{Operators!solvetridiag}
\index{Operators!solv\_bandmat}
\index{Operators!decompLU}
\index{Operators!backsubLU}
\index{Operators!invertLU}
\index{Operators!bandLU}
\index{Operators!bandbs}
\index{Operators!complexFFT}
\index{Operators!realFFT}
\index{Operators!sineFFT}




\emph{matmul} forms the matrix product $c = a \ast b$. Each matrix is described as a list of row arrays. The number of columns in \emph{a} must equal the number of rows in \emph{b}, and in \emph{c} the number of rows is the same as in \emph{a} and the number of columns is the same as in \emph{b}. All arrays are of type `/D'. \emph{mattranspose} transposes matrix \emph{a} and returns the result in matrix \emph{b} (the number of colums in \emph{a} equals the number of rows in \emph{b}, and the number of rows in \emph{a} equals the number of columns in \emph{b}). \emph{matvecmul} forms the product $c = a \ast b$ of the matrix \emph{a} with the column vector \emph{b} (given as an array) and returns the result in column vector \emph{c} (an array). (If matrix \emph{a} is $m \times n$ then \emph{b} is of dimension $n$ and \emph{c} is of dimension $n$). These matrix operators are multi-threaded (like the common mathematical operators).

\emph{integrateOH} forms a running sum of array elements in place using the one-half rule of integration (it takes arrays of all types and it returns twice the sum). \emph{integrateRS} forms the simple running sum of a `/D' type array. \emph{integrateOHv} takes any type of ordinate array and replaces its value by twice the running integral based on the one-half rule and the (generally non-uniform) abscissa intervals given in \emph{dx\_array} (which needs not match the type of \emph{y\_array}).

\emph{solvetridiag} takes five array operands all matching in type (either `/S' or `/D'): \emph{a} holds the subdiagonal matrix elements (the first element is ignored); \emph{b}, the diagonal elements; \emph{c}, the supradiagonal elements (the last element is ignored); \emph{r}, the right-hand sides; \emph{u} receives the solution of the tridiagonal linear equations system. The boolean indicates whether a valid solution was obtained.

\emph{solve\_bandmat} solves a linear equation system whose coefficients are a bandmatrix (based on \emph{bandet1} and \emph{bansol1} of Wilkinson/Reinsch I/6). The list \emph{bandlist} contains the coefficients as band arrays running parallel to the main diagonal and starting with the bottom-most diagonal; the index of the main diagonal array in \emph{bandlist} is given by the numeral \emph{main\_idx}. The first element of all band arrays corresponds to the first column of the matrix; positions falling outside the matrix must be filled by zeroes. \emph{bandrh} provides the right-hand side vector and is overwritten by the solution, whose validity is indicated by \emph{bool}. All arrays must have identical dimensions and type `/D'.

\emph{decompLU} performs the LU-decomposition of the matrix \emph{a} in place (given as a list of row arrays of type `/D'). The array \emph{idx} is of type `/X' and receives row permutation information to be used by \emph{backsubLU}. The returned numeral \emph{d} signals an even/odd number of permutations, and \emph{bool} signals a valid decomposition (or a singular matrix). \emph{backsubLU} computes the solution of a linear equation system using the LU-decomposed coefficient matrix \emph{a} with the permutation information \emph{idx} and a column vector of right-hand values \emph{b}, which is overwritten by the solution. \emph{invertLU} inverts the matrix \emph{a} and returns the inverse in matrix \emph{b} (internally using LU-decomposition and repeated backsubstitution); upon return, \emph{a} and array \emph{idx} contain the LU-decomposed matrix and row permutation information. A \op*{false} value of \emph{bool} signals singularity of the matrix.

\emph{bandLU} performs the LU-decomposition of a bandmatrix described by \emph{bandlist} and \emph{main\_idx} (see \emph{solve\_bandmat}) and returns the results in \emph{bandlist}, the bandmatrix buffer \emph{llist}, and the `/X' array \emph{idx} (see \emph{decompLU}). \emph{bool} is set false when singularity is discovered. For details see Press et al. 2.4. \emph{bandbs} computes a solution of the banded linear equation system for the right-hand vector given in array \emph{b}, which overwrites the vector.  

\emph{complexFFT} perform the FFT transform on an array of complex numbers (presented as alternating real and imaginary parts) in place, in the direction specified by \emph{dir} (1 - forward, -1 - inverse). The array is of type `/D' and its dimension is a power of two. \emph{realFFT} performs the forward transform on an array of real numbers, returning in the modified array: real parts of first and last spectral point, then alternating real and imaginary parts up to the Nyquist frequency. \emph{sineFFT} takes an array of real numbers and returns the real amplitudes of the sine spectrum and vice versa, as directed by \emph{dir}. Sequential application of the forward and reverse transforms reproduces the original array data in all forms of these FFT transforms.
   

       
\subsection{More mathematical operators (`blas' and `lp' styles)}

The operators of this group are based on matrix-algebra libraries that have been imported into the D machine (BLAS and LAPACK). These libraries accept matrices that are mapped in a variety of possible ways on memory for minimizing space demands while maintaining efficient access. We have implemented at this time only the general matrix. Maps for banded or other forms of sparse matrices could be implemented, but are not at this time. 

Although these linear-algebra operators use only vectors and matrices, we base their usage on a general map that projects a n-dimensional array onto a one-dimensional D array. The D array is dimensioned to hold (at least) the entire value of the n-dimensional array. The projection is separately described by a \emph{map}, which is in the form of a list of numerals\\

\begin{equation}
[ N N_{-1} N_{-2} \ldots N_{-n} ]
\end{equation}

\noindent where $N$ is the product of all dimensions, $N_{-1}$ the product of the $n-1$ dimensions excluding that of the highest-ranked dimension, and so on, down to and including $N_{-n}=1$ (the last element, although trivial, is necessary to consistently describe arrays of any number of dimensions including zero).

The form of the \emph{map} facilitates the mapping of elements of the next-lower array dimension, an operation that can be repeatedly applied down to the zero-order dimension if a simple element of the n-dimensional array is to be mapped. Since the data storage and the map describing it are separate, a D array can be used with multiple maps to create a variety of multi-dimensional arrays. Storage efficiency extends to the maps themselves because submaps created in the operation of accessing array elements are children objects of the full map rather than created new.\\

 \begin{tabular}{>{\sffamily}r>{\sffamily\bfseries}l>{\sffamily}l}
[ dimensions ] & map & map\\
array map i & ss & subarray submap\\\\
\end{tabular}

\emph{map} converts a list of dimensions into a list holding the corresponding map (this is done in place). The dimensions are given in descending order; the lowest-ranked dimension is $1$.

The `subscript' operator has been given a short name, \emph{ss}. It returns the subarray of \emph{array} holding the highest-order $i$-th element of the multi-dimensional organization described by \emph{map}; it also returns the map of the subarray (which is the sublist of \emph{map} comprising the second and following elements of \emph{map}). Repeated use of \emph{ss} yields descriptions of lower- and lower-ranked elements of the multi-dimensional array.\\

\begin{tabular}{>{\sffamily}l}
[ 15 20 100 1 ] map dup /Amap name 0 get /d array /A name\\
A Amap 2 ss 9 ss 12 ss /amap name /a name\\\\
\end{tabular}

\noindent This example defines \emph{A} as a three-dimensional array
and associates it with the map \emph{Amap}. Then performs three rounds
of indexing to extract element $a_{2,9,12}$. This returns the map of a
zero-dimensional array (as the D list [1]), and the zero-dimensional
array containing the element (as a D array of length 1).

The `blas' and `lp' operators are executed using the cache facilities
and processors in the host of the \dcomp{dnode}. They do not
themselves distribute work among different hosts in a cluster.

\begin{formulas}
matmul_blas      & C & \alpha A^{t?} B^{t?} + \beta C \\
matvecmul_blas   & y & \alpha A^{t?} x + \beta y      \\
solvetriang_blas & x & A^{t?,-1} x                    \\
\end{formulas}

\begin{definitions}
givens_blas      & compute Givens transformation \\
rotate_blas      & rotate\\
norm2_blas       & compute $\lVert x \rVert _2$\\
decompLU_blas    & compute LU decomposition of $A$\\
backsubLU_blas   & compute LU backsubstitution with RHS\\
invertLU_blas    & compute inverse matrix following LU decomposition\\
\end{definitions}

\begin{ops}
C Cmap beta A Amap Atrans       !
B Bmap Btrans alpha             & matmul_blas      & C Cmap \\
y beta A Amap Atrans x alpha    & matvecmul_blas   & y \\
x12                             & givens_blas      & c s \\
c s x y                         & rotate_blas      & x y \\
x                               & norm2_blas       & num \\
x A Amap Atrans upper unit      & solvetriang_blas & x \\
A Amap pivot                    & decompLU_lp      & A Amap pivot true \\
                                &                    & false\\
rhs A Amap pivot                & backsubLU_lp     & rhs \\
A Amap pivot                    & invertLU_lp      & A Amap \\\\
\end{ops}

The operands specified as capitalized names (e.g., \emph{A}) are /D
arrays holding matrix data, described by a map (\emph{Amap}). A
boolean (\emph{Atrans}) when true designates use of the transposed
matrix rather than the matrix itself. Names in greek letters stand for
/D scalars, and lower-case names are vectors (/D arrays), a /L array
(\emph{pivot}), or /D scalars (\emph{c}, \emph{s}).

\op{matmul_blas} and \op{matvecmul_blas} perform generalized
matrix-matrix or matrix-vector multiplications.

\op{givens_blas} computes the cosine (\emph{c}) and sine (\emph{s}) of
a Givens transformation for a two-element vector \emph{h}, overwriting
the vector. The plane Givens rotation on a pair of vectors \emph{x}
and \emph{y} is effected in place by \op{rotate_blas}.

\op{solvetriang_blas} solves the linear system with the triangular
coefficient matrix \emph{A} where the boolean \emph{upper} indicates
in which half of \emph{A} the triangular coefficients are located; the
boolean \emph{unit} forces unit diagonal elements regardless of their
values in \emph{A}. The vector \emph{x} contains the right hand side
on input and the solution on output.

\op{decompLU_lp} performs the LU-decomposition of matrix \emph{A} in
place and inserts pivoting information into the vector
\emph{pivot}. The decomposed matrix and pivoting are used by
\op{backsubLU_lp} and \op{invertLU_lp} to generate a solution given
for a right-hand-side vector (returning it in the vector), or to
compute the inverse of the decomposed matrix in place.
 
 
Some of these operators return a boolean indicating success/failure of
the attempted operation. Others (e.g., \op{solvetriang_blas}) can
also fail, but, for reasons due to error-reporting quirks of the
BLAS/LAPACK libraries, report an operator error via the \op{error}
mechanism of the D \dcomp{dnode}. An additional message detailing the
error reported by the library is written to `stderr' (which you may
wish to redirect to a log file for having an ear at the horse's
mouth).

\subsection{Communicating with a cluster of \dcomp[dpawn]{dpawns}}

\begin{ops}
  [ n1 dict1 n2 dict2 \ldots ] & makerthreads  & socket \\
  null                         & makerthreads  & --     \\
--                             & rthreads      & n      \\
--                             & checkrthreads & bool   \\
  idx active_obj / string      & rsend         & --     \\
  socket comp_obj              & send          & --     \\
  sig                          & rsendsig      & --     \\\\
\end{ops}

A cluster of \dcomp[dpawn]{dpawns} is created on the network by
\op{makerthreads} (make remote threads). The list argument of the
operator generally has several to many paired entries. The first item
of a pair gives the number of \dcomp[dpawn]{dpawns} to be brought up
on the Linux box described by the second item, a dictionary. The
dictionary is specific for the \emph{mpi} environment and provides,
under \emph{mpi}-specific names a set of associated
strings. \op{makethreads} starts a child process of the \dcomp{dnode}
called the `rook'. The rook mediates communications between the
\dcomp{dnode} and \dcomp[dpawn]{dpawns} via
\emph{mpi}. \op{makerthreads} returns a socket (i.e. socket-type null
object) for communication with the rook via the \dcomp{dnode} operator
\op{send} (see below). Messages sent by \dcomp[dpawn]{dpawns} to the
\dcomp{dnode} will be addressed (via \emph{mpi}) to the rook, who
communicates them to the \dcomp{dnode} through the socket established
by \op{makethreads}. A second usage of \op{makerthreads}, taking a
\op*{null} argument, kills the rook and the current
\dcomp[dpawn]{dpawns} (it returns nothing). The rook is used to couple
\dcomp{dnode} and \dcomp[dpawn]{dpawns} in this way in order to
facilitate cleanup of failed \dcomp{dpawn} activities without
compromising the continuity of the \dcomp{dnode} itself.

\op{rthreads} inquires the current number of \dcomp[dpawn]{dpawns},
independent of their functional states. \op{checkrthreads} returns
\op*{true} if the rook and all current \dcomp[dpawn]{dpawns} are
responsive. If the rook is unresponsive, \op{checkrthreads} eliminates
all remote threads from the \dcomp{dnode} and returns \op*{false}. If
one or more \dcomp[dpawn]{dpawns} are unresponsive, \op{checkrthreads}
simply returns \op*{false}.

You can send messages to the rook using \op{send} with the socket
number obtained from \op{makerthreads}. The rook will broadcast such a
message to all current \dcomp[dpawn]{dpawns}. The standard method for
transmitting messages to \dcomp[dpawn]{dpawns}, however, is
\op{rsend}. To identify a particular \dcomp{dpawn} as target, specify
its index \emph{idx} (automatically assigned by \op{makerthreads} in
the order of its argument list elements, starting from 0). To send to
all current \dcomp[dpawn]{dpawns}, specify \emph{idx} as `undefined'
(*). The active object or string will be submitted to the target
\emph{dpawn(s)} for execution (see also \op{send}).

\op{rsendsig} sends a signal to all pawns, where the signal is an
integer that is mapped in the source file \file{dm-signals.c} as
\texttt{sigmap} to a signal number for the current platform. However,
these mappings are identified by name in the dictionary
\proc{SIGNALS}, which has such members as \textproc{QUIT} and
\textproc{KILL}, which are the proper enumeration to send a
\texttt{SIGQUIT} or \texttt{SIGKILL} to all pawns. See the
\op{sendsig} operator which functions similarly for \dcomp{dvt} and
\dcomp{dnode} machines.

\pagebreak
\subsection{The PETSc procedure library of the \dcomp{dnode}}
\label{section:petsc-procs}
\begin{procs}
   /A \ldots /type rows columns & mat_create      & A \\
                      /X length & vec_create      & X \\
                           /Y X & vec_dup         & Y \\
                         X data & vec_fill        & -- \\
                   A ~row-maker & mat_fill        & -- \\
                        X data  & get_vector      & data \\
                         A data & get_matrix      & data \\
                           /B A & mat_dup         & B\\
                       \ldots A & mat_transpose   & --\\
        Y beta A Atrans X alpha & pmatvecmul      & -- \\
   data Y beta A Atrans X alpha & get_matvecmul   & data \\
                          /name & ksp_create      & K \\
                              X & vec_destroy     & -- \\
                              A & mat_destroy     & --\\
                              K & ksp_destroy     & --\\
                        K A X Y & ksp_solve       & --\\
                          K X Y & ksp_resolve     & --\\
                   K A X Y data & get_ksp_solve   & data\\
                     K X Y data & get_ksp_resolve & data\\
                           bool & report          & --\\
                 length ~active & execrange       & --\\
\end{procs}

These procedures internally communicate with a cluster of
\dcomp[dpawn]{dpawns} where they initiate operations involving PETSc
operators (see section~\ref{section:petsc-ops}). The \dcomp{dnode}
keeps records of the PETSc objects that are created in the form of
dictionaries (referenced as $A$ or $B$ for matrices in the table, $X$
or $Y$ for vectors, and $K$ for solvers). Currently three varieties of
PETSc object are represented this way:

\begin{dict}[vec]{Vector dictionary}
  id & name\\
  N  & length\\
\end{dict}

The \textproc{id} is the name used when creating the PETSc
object. \textproc{N} is the length of the vector.

\begin{dict}[mat]{Matrix dictionary}
  id     & name\\
  m      & global rows\\
  n      & global columns\\
  mtype  & matrix type\\
  params & dictionary of type-specific parameters\\
  mmax   & the maximum number of local rows on any matrix\\
\end{dict}

\textproc{mtype} is a name defining the format of the matrix:
\textproc{/sparse}, \textproc{/dense} or
\textproc{blockdense}. \textproc{mmax} is the number of rows on the
last pawn: if there are 9 rows and 4 pawns, \textproc{mmax} would be
$3$. \textproc{params} is a dictionary whose format is associate with
\textproc{mtype}.

\begin{dict}[sparse]{Sparse Matrix Parameter dictionary}
  irows     & row offsets                                \\
  icols     & column associated with each non-zero datum \\
  icols_off & list of global row offsets                 \\
\end{dict}

\textproc{irows} and \textproc{icols} are active names defining the
CSR format for the matrix. On each pawn, \textproc{irows} has a length
equal to the number of rows on that pawn plus one; each element
defines the offset into the data (and \textproc{icols}) of the start
of a row, in order, and the last element gives the offset of the the
last element of the data plus one. On each pawn, \textproc{icols} is
the same size as the number of non-zero elements of the data, and
holds the column number for the associated datum. \textproc{icols_off}
is a list of the offsets of the first row on each pawn into the global
matrix. The names pointed to by \textproc{irows} and \textproc{icols}
are defined by the user on each pawn, but \textproc{icols_off} is
transparently created by the \emph{petsc} \emph{D} procedures.

For \textproc{/dense} and \textproc{/blockdense} types, the param dict
is empty.

\begin{dict}[krylov]{Krylov Space Solver dictionary}
  id          & name\\
  rtol        & relative tolerance (1e-12)\\
  atol        & absolute tolerance (*)\\
  dtol        & divergence tolerance (1/rtol)\\
  maxits      & maximal number of iterations\\
  pctype      & type of preconditioner (*, i.e. JACOBI)\\
  ksptype     & type of ksp solver (*, i.e. GMRES)\\
  kspparam    & parameters for the ksp type (null)\\
  pcparam     & parameters for preconditioner type (null)\\
  monitortype & type of the monitor for ksp solves (*, i.e. petsc default) \\
\end{dict}

\textproc{rtol} and \textproc{atol} are the tolerances for convergence
tests.  Convergence is detected if $||r_k||_2 < max(rtol * ||b||_2,\;
atol)$, where $r_k = b - Ax_k$. On the other hand, \textproc{dtol} is
the tolerance for detecting divergence: $||r_k||_2 > dtol *
||b||_2$. \textproc{maxits} is the number of iterations before
divergence is assumed. If any of these are set to $*$, the
\emph{petsc} defaults are used. See \citet[Section~4.3.2]{balay:2004}
for a discussion of these defaults.

\textproc{ksptype}, \textproc{pctype}, and \textproc{monitortype} are
integers that map to a solver, a preconditioner, and a monitoring
output for the latter. The integers are defined in \file{dmpetsc.c} in
the structures \texttt{ksptypes}, \texttt{pctypes}, and
\texttt{monitors}. The names for use from \emph{D} are defined in the
dictionaries \textproc{ksptypes}, \textproc{pctypes},
\textproc{monitorytypes} defined by \file{petsc.d} in the
\textproc{PETSC} module.

Associated with \textproc{ksptype} is \textproc{kspparam}, and with
\textproc{pctype} is \textproc{pcparam}. The `*param' names map to
\emph{D} objects that are necessary for the solver (and its
preconditioner). Currently, none of the defined types use them - both
should be \textop{null}.

\proc{mat_create} creates a matrix distributed over the
\dcomp[dpawn]{dpawns}. The \textproc{rows} and \textproc{columns}
operands are the global size of the matrix. The \textproc{/A} operand
is the name of the matrix, from the point of view of the pawns;
usually, this will also be what you call the output reference
dictionary. The \textproc{/type} operand is a name:
\textproc{/sparse}, \textproc{/dense} or \textproc{/blockdense}. That
type determines the parameters representde by `\ldots'. This procedure
returns a dictionary as in table~\ref{dict:mat}.

For sparse, the parameters are: \textproc{~irows}
\textproc{~icols}. \textproc{~irows} is a name that has been defined,
on the pawns, to return the offsets into the local data for the
beginning of each row, while \textproc{~icols} returns on the pawns
the column number for location in the matrix. This a local CSR
format. For dense and blockdense, there are no extra operands.

\proc{vec_create} creates a vector distributed over the pawns. The
\textproc{/X} parameter is the name of the vector on the pawns, which
should usually be the same as the name of the dictionary referencing
the vecotor, and \textproc{length} is the global length of the
vector. This procedure return a dictionary referencing the vector, as
defined in table~\ref{dict:vec}. \proc{vec_dup} replicates the vector
\textproc{X} as \textproc{/Y} on the pawns, including data. It returns
a new vector dictionary for the \dcomp{dnode}. 

\proc{vec_fill} copies the d-array data, referenced by the name
\textproc{~data} on each pawn for the local portion, into the vector
replacing current values. \proc{mat_fill} does the same for matrices,
but instead of referencing a d-array, the last parameter references a
procedure, the \textproc{row_maker}: \\
\begin{procs}
  A row & row\_maker & data icols    \\
\end{procs}                          \\
where \textproc{A} is the matrix (see the pawn petsc operators,
section~\ref{section:petsc-ops}), \textproc{row} is the local row
number to be filled, \textproc{data} is the d-array to copy into that
row, and \textproc{icols} are the column numbers of each of the
elements of that row.

\proc{get_vector} collects all the data for vector \textproc{X} into
\textproc{data}, which is just a D array of doubles. The call returns
the sub-array into which \textproc{X} fits. \proc{get_matrix} does the
same for a matrix: the elements (non-zero for a sparse matrix) of the
matrix are inserted into a D array of doubles.

\begin{formulas}
  pmatvecmul      & y & \beta y + \alpha A^{t?} x \\
  get_matvecmul   & y & \beta y + \alpha A^{t?} x \\
  ksp_solve       & x & A^{-1} y                  \\
  ksp_resolve     & x & A^{-1} y                  \\
  get_ksp_solve   & x & A^{-1} y                  \\
  get_ksp_resolve & x & A^{-1} y                  \\
\end{formulas}

\proc{pmatvecmul} and \proc{get_matvecmul} multiply the (possibly
transposed) matrix by a vector, and add it to a scale vector,
returning the value in that latter vector. The `get' version returns
the resultantant vector to the dnode.

\proc{mat_dup} creates a new matrix $B$ from a matrix $A$, and then
copies the non-zero elements from $A$ to $B$. \textproc{mat_transpose}
transposes a matrix $A$, keeping the same identifier. The latter
requires varying parameters according to type: For \textproc{/sparse},
the parameters are \textproc{~irows} \textproc{~icols}, where
\textproc{~irows} is the name to use on the \dcomp[dpawns]{dpawn} for
the row data, and likewise for the \textproc{~icols}. See
\textproc{mat_create} for further explanation: the only difference
here is that they aren't predefined on the \dcomp[dpawns]{dpawn}, but
are created by this procedure. For \textproc{/dense} type matrices,
the optional parameters are empty.

\proc{ksp_solve}, \proc{ksp_resolve}, \proc{get_ksp_solve} and
\proc{get_ksp_resolve} all use an iterative solver to calculate
$A^{-1}y$. The `re' versions solve for a new $x$ from $y$, given that
the matrix $A$ is unchanged for the solver. The `get' versions return
the resultant $x$ to the dnode. So, \proc{ksp_solve} must be called
once with a matrix $A$ and solver $K$, and then $K$ may be used with
\proc{ksp_resolve} to avoid pre-conditioning $A$ again.

An important element of ksp reuse is that any new matrix $A_n$ must
have an identical structure to the previous matrix $A_o$. This is
guaranteed by testing that the $A_n$ was created by some sequence of
calls to \proc{mat_dup} on $A_o$.

The solver is created by calling \proc{ksp_create}, with a
\dcomp{dnode} name. The currently defined \textproc{kspsettings}
dictionary is used for the solver parameters, as defined in
table~\ref{dict:krylov} (except for \textproc{id}, which is the
parameter passed on the stack). It returns that a copy of that
dictionary, with the \textproc{id} filled in. In \textproc{PETSC},
dictionaries have predefined names for the numeric parameters:
\textproc{ksptypes} for \textproc{ksptype}, \textproc{pctypes} for
\textproc{pctype} and \textproc{monitortypes} for
\textproc{monitortype}. As of this writing, none of the defined
\textproc{ksptypes} or \textproc{pctypes} use \textproc{kspparam} or
\textproc{pcparam}, respectively.

The procedures \textproc{ksp_destroy}, \textproc{mat_destroy},
\textproc{vec_destroy} all eliminate the parameter (of the matching
type). They \op{restore} the box associated with the \dcomp{dnode} and
\dcomp{dpawn} dictionaries, and un-allocate any external memory used
by the PETSc libraries (and are therefore preferred to simply
\op{restore}'ing a box that contains the dictionaries). PETSc external
memory allocation only occurs on the \dcomp[dpawns]{dpawn}, and not on
the \dcomp{dnode}.

\proc{report} simply turns on or off verbose reporting
(\textproc{true} to turn verbose reporting on).

\proc{execrange} runs an active object on all \dcomp[dpawns]{dpawns},
passing in the range for that pawn in particular. It should be used
for initializing per-pawn data and parameters for vectors and
matrices. The parameter \textproc{length} is chopped up into (offset,
length) pairs for each node, which is passed to \textproc{~active} on
the pawn. So, with 5 pawns and a length of 11, the first four pawns
run \textproc{~active} with $0$ $2$, $2$ $2$, $4$ $2$, and $6$ $2$ on
the stack, while the last pawn runs \textproc{~active} with $8$ $3$ on
the stack.


\section{The D pawn (\dcomp{dpawn})}

The \emph{pawn} variety of D machine is created and killed by
operators of a supervising \dcomp{dnode}. The \dcomp{dpawn} includes the
general-purpose operators also available to a \dcomp{dnode}, uses a
different set of communication operators based on the \emph{mpi}
protocol, and taps the computational facilities of the PETSc library
through D operators that map to PETSc library functions.

The operator set of a \dcomp{dpawn} differs from that of a
\dcomp{dnode} in the following ways:
\begin{itemize}
\item The operators \\
\begin{tabular}{>{\sffamily\bfseries}l}
console             \\
setconsole          \\
getmyport           \\
Xconnect            \\
Xdisconnect         \\
\end{tabular}
\end{itemize}

\subsection{Operators for administrating a \dcomp{dpawn}}

Most of these operators are synomymous with \dcomp{dnode} operators but
have slightly different behaviors.

\begin{ops}
                      long_array/null  & vmresize     & bool\\
                                    -- & halt         & --\\
                                    -- & continue     & --\\
                                    -- & stop         & --\\
                                    -- & abort        & --\\
                              active_obj & lock         & --\\ 
                                    -- & console      & consolesocket/null\\
                      consolesocket/null & setconsole   & --\\
                                  string & toconsole    & --\\
                                  string & tostderr     & --\\
       hostname port# !
sourcestr numerr & error        & --\\
hostname port# sourcestr!
 numerr strbuf & errormessage & messstr\\
                                    -- & getmyport    & port#\\
                                    -- & Xwindows_    & bool\\
                    (hostname:screen#) & Xconnect     & --\\
                                    -- & Xdisconnect  & -- \\
                                     num & makethreads  & --\\ 
                                    -- & threads      & num\\ 
                            active_obj & serialize    & --\\
                                    -- & getlibdir    & string\\
                       (path) (filename) & loadlib      & lib_dict\\
                                    -- & hi           & (library description)\\
                                    -- & libnum       & num\\
                         null/lib_dict & nextlib      & dict true\\
                                       &                & false\\\\
\end{ops}

\subsection{Operators for communicating via \emph{mpi}}

\paragraph{NB: Not tested yet.} These operators are for inter-pawn
communications. They can be individual, collective or
source-destination.

\subsubsection{Individual}

Individual operators are run on one pawn to produce global or local
data about the network of mpi processes.

\begin{ops}
 -- & mpirank & rank\\
 -- & mpisize & size\\\\
\end{ops}

These two operators define the relationship between the current
process and all other \dcomp[dpawn]{dpawns}.
\op{mpirank} returns the rank id of the current process. This is an
integer from the range $[0\ldots n)$, where $n$ is the \op{mpisize}
of the system. It is an arbitrary id number, but by convention in the
mpi world rank $0$ does any sequential or global activity.

\op{mpisize} returns the total number of mpi processes.

\subsubsection{Collective}

Collective operators must be run on \emph{all} mpi
processes. Processes will block until all other processes have at
least entered the operator.

\begin{ops}
-- & mpibarrier & --\\
root object & mpibroadcast & object\\\\
\end{ops}

\op{mpibarrier} is a synchronization operator. All processes block
until all other processes have entered the barrier. In other words, no
operations after \op{mpibarrier} on any process begin until all
operations before \op{mpibarrier} on all processes have ended.

\op{mpibroadcast} sends an object to all processes. The ``root''
process is the sender of the object; all other processes are the
receivers. For the receivers, the input object may be null (it is
discarded). For the sender, the output object is the same as the
original. The root integer is the \op{mpirank} of the sender.

\subsubsection{Source-destination}

Source-destination operators work as pairs, where one process
initiates the operation with an operator, and another process
completes the operation with a different operator.

\begin{ops}
dest object & mpisend   & --\\
src         & mpirecv   & object\\
src         & mpiprobe  & src!
*           &             & src\\
src         & mpiiprobe & src true!
src         &             & false!
*           &             & src true!
*           &             & false\\\\
\end{ops}

\op{mpisend} sends the object to the destination, as identified by its
\op{mpirank}. It may or may not block while sending, so you must
guarantee that the receiver will eventually call \op{mpirecv}, and
that no deadlocks will occur.

\op{mpirecv} is the matching operator to \op{mpisend}, returning
the object sent from the source. It will block until an object is sent
by the source process (as identified by it's \op{mpirank}).

\op{mpiprobe} and \op{mpiiprobe} check for objects being sent by
mpi processes to the current process. They can either check for a
message from a specific process when called with a process's
\op{mpirank}, or if they are called with `*' (undefined) they will
probe for messages from any process, returning the rank of the sender
to the caller. The difference between the two is in blocking behavior:
\op{mpiprobe} blocks until at least one message is queued to be
received, while \op{mpiiprobe} returns false if no message is
pending and true if a message is pending (in addition to the source
id). Broadcast messages from \op{mpibroadcast} can not be probed
for.

\subsection{The PETSc operator library of the \dcomp{dpawn}}
\label{section:petsc-ops}
\begin{ops}
                    size & petsc_vec_create            & X                 \\
                       X & petsc_vec_dup               & Y                 \\
                     X Y & petsc_vec_copy              & Y                 \\
                       X & petsc_vec_syncto            & X                 \\
           data offset X & petsc_vec_copyto            & X                 \\
                       X & petsc_vec_syncfrom          & X                 \\
           X offset data & petsc_vec_copyfrom          & data              \\
                       X & petsc_vec_max               & max               \\
                       X & petsc_vec_min               & min               \\
                       X & petsc_vec_destroy           & --                \\
                       X & petsc_vec_norm              & norm              \\
            rows columns & petsc_mat_dense_create      & A                 \\
<l irows> <l icols> columns 
                         & petsc_mat_sparse_create     & A                 \\
rows-per-process!
columns-per-process!
            rows columns & petsc_mat_blockdense_create & A                 \\
                       A & petsc_mat_destroy           & --                \\
                     A B & pesc_mat_copy               & B                 \\
                       A & petsc_mat_dup               & B                 \\
                       A & petsc_mat_syncto            & A                 \\
                       A & petsc_mat_syncfill          & A                 \\
                       A & petsc_mat_endfill           & A                 \\
              
 <d data> <l cols> row A & petsc_mat_fill              & A                 \\
 <d data> row
          start-column A & petsc_mat_copyto            & A                 \\
                       A & petsc_mat_syncfrom          & A                 \\
 A row 
   start-column <d data> & petsc_mat_copyfrom          & <d data>          \\
 A                       & petsc_mat_transpose         & A|$^t$|           \\
                       A & petsc_mat_getnz             & num-nonzeros      \\
   <l rows> <l cols> A   & petsc_mat_getcsr            & <l rows> <l cols> \\
 Y beta A transA X alpha & petsc_mat_vecmul            & Y                 \\
ksptype kspparam pctype!
pcparam monitortype      & petsc_ksp_create            & K                 \\
                       K & petsc_ksp_destroy           & --                \\
 K rtol atol dtol maxits & petsc_ksp_tol               & --                \\
            K A/null X B & petsc_ksp_solve             & X                 \\
                      -- & petsc_log_begin             & --                \\
      (dir) (filename)   & petsc_log_summary           & --                \\
\end{ops}

These are the primitive operators called on a \dcomp{dpawn} to create
and manipulate petsc objects. They are primarily collective in nature,
in the \emph{mpi} sense: they must be called on each pawn
independently but synchronistically. Therefore, these are primarily
intended to be internal operators, called indirectly via procedures on
the \dcomp{dnode} (see section~\ref{section:petsc-procs}).

They work on three different objects produced by the \file{dmpetsc.c}
plugin. Each is a D dictionary that encapsulates petsc data structures
and memory allocations:

\begin{dict}[petsc-vec]{dm\_petsc\_vector}
    VECTOR_VECTOR & integerized pointer locating the petsc vector \\
    VECTOR_N      & the local number of elements                  \\
    VECTOR_GN     & the global number of elements                 \\
    VECTOR_ASS    & boolean that signals whether the vector!
                  & has been assembled by the petsc libraries     \\
\end{dict}

\begin{dict}[petsc-mat]{dm\_petsc\_matrix}
    MATRIX_MATRIX & integerized pointer locating the petsc matrix \\
    MATRIX_M      & local number of rows                          \\
    MATRIX_N      & local number of columns                       \\
    MATRIX_GM     & global number of rows                         \\
    MATRIX_ASS    & boolean that signals whether the matrix!
                  & has been assembled by the petsc libraries     \\
    MATRIX_DUPID  & integer identifying the structure !
                  & a duplicate has the same dupid,!
                  & and can be used with the same ksp          \\
    MATRIX_MTYPE  & an integer identifying the type of the matrix:!
                  & sparse, or dense\\
\end{dict}

\begin{dict}[petsc-ksp]{dm\_petsc\_ksp}
  KSP_KSP        & integerized pointer locating the petsc ksp \\
  KSP_N          & The number of columns in the matrix and vectors!
                 & associated with this ksp                   \\
  KSP_KSPTYPE    & An integer identifying the solver type, !
                 & as mapped to from \textproc{ksptypes} !
                 & in \textproc{PETSC}\\
  KSP_PCTYPE     & An integer identifyint the preconditioner type, !
                 & as mapped to from \textproc{pctypes} !
                 & in \textproc{PETSC}\\
  KSP_DUPID      & An integer identifying the matrix `structure':!
                 & once initialized, it will be identical to the !
                 & \textproc{MATRIX_DUPID} of matrices that !
                 & may be used with this ksp         \\
  KSP_PCSETUPFD  & an integerized pointer to internal data !
                 & for initializing the preconditions \\
  KSP_KSPSETUPFD & an integerized pointer to internal data !
                 & for initializing the solver\\
\end{dict}

\op{petsc_vec_create} creates a vector of a given \emph{local
  length}. \op{petsc_vec_dup} duplicates a vector into a new vector of
the same length, but without the elements being
initialized. \op{petsc_vec_copy} copies the data from a vector $X$
into a vector $Y$ of the same length.

\op{petsc_vec_copyto} copies data elements from a D double array into
a vector, starting at element $n$. Of course, the length of the array
+ $n$ must be less than or equal to the length of the
vector. \op{petsc_vec_syncto} must be called on idling pawns when
\op{petsc_vec_copyto} is called: in otherwords, the combination of the
two operators is collective.

\op{petsc_vec_copyfrom} is the inverse operation: it copies the
elements of a vector, starting at $n$, into an a D array. The number
of elements copied is the length of the array or the length of the
vector - $n$ (which ever is smaller), and the sub-array of that length
is returned. \op{petsc_vec_syncfrom} is used for idling pawns during
this operation: the union of both operators is collective.

\op{petsc_vec_max} and \op{petsc_vec_min} are collective operator that
return on every pawn the \emph{global} max and min, respectively, of a
vector. \op{petsc_vec_norm} returns on every pawn the \emph{global}
length of the vector ($\scriptstyle||X||=\sqrt{\sum_i X_i^2}$).

Finally, \op{petsc_vec_destroy} should be called to deallocate a
vector: it destroys the dictionary and any internal petsc data
structures associated with the vector. Use solely of
\op{save}-\op{restore} pairs will leak through the PETSc libraries.

\op{petsc_mat_dense_create} creates an empty matrix of a given numer
of rows and columns. \op{petsc_mat_sparse_create} creates a sparse
matrix whose structure is defined by a maximum number of columns and
CSR pair of long D arrays: the offset into the column array for the
beginning of each row, and the filled columns; of course, the last
element of the row array is one past the last
column. \op{petsc_mat_blockdense_create} creates a block-dense matrix,
which has blocks defined by the number of columns per pawn, and rows
per pawn.

All these matrix types are cleaned-up by the single
\op{petsc_mat_destroy} operator, which both eliminates the dictionary
and cleans up any PETSc data structures associated with it.

\op{petsc_mat_dup} duplicates a matrix, creating a new matrix with the
same structure as the original, both type and
layout. \op{petsc_mat_copy} copies the data from a matrix to a matrix
with the same non-zero pattern (but it needs not be a duplicate).

\op{petsc_mat_fill} copies data from a D double array into elements of
a row of a matrix. The mapping is defined by a long array of the same
length of the data array which identifies the column number for each
data element. The row number $m$ is the \emph{local} row number. On
idling pawns, \op{petsc_mat_syncfill} must be called: the combination
of these two calls are collective. When done filling the rows of a
matrix, \op{petsc_mat_endfill} must be called to assemble the matrix:
this actually handles beginning the communications between different
pawns about their updated elements. No other PETSc calls can be made
on the matrix between the initial
\op{petsc_mat_fill}/\op{petsc_mat_syncfill} and the final
\op{petsc_mat_endfill} on all pawns.

Similarly, \op{petsc_mat_copyto} copies the elements of a D array into
a \emph{local} row of the matrix, starting at a given column
number. It fills all the `non-zero' elements of the rows until the
input array is exhausted. All idling pawns must call
\op{petsc_syncto}. On the other hand, \op{petsc_mat_copyfrom} copies
from a \emph{local} row of the matrix starting at a given column
number into a D array, until it runs out of columns or exhausts the D
array. \op{petsc_mat_syncfrom} must be called on idling pawns.

\op{petsc_mat_transpose} transpose the data of a matrix. After this
operation, the matrix $A$ will no longer be a duplicate of it's
earlier state (i.e., can not be used with an ksp).

\op{petsc_mat_getnz} returns the total number \emph{local} non-zero
elements. This can be used to construct the arrays for
\op{petsc_mat_getcsr}, which fills an array with the CSR structure of
the matrix: an array of offsets for the beginning of each row, into an
array of column numbers.

\op{petsc_vec_matmul} evaluates $y \leftarrow \beta y + \alpha Ax$,
where $y$ and $x$ are vectors and $A$ is a matrix. If $\beta$ is $0$
(the integer), the shortcut $y \leftarrow \alpha Ax$ is applied, and
if $\beta$ is $1$ (the integer), the shortcut $y \leftarrow y + \alpha
Ax$ is applied.

\op{petsc_ksp_create} creates a solver object (`ksp'). The parameter
`ksptype' is an integer, as enumerated in \textproc{ksptypes} of
\textproc{PETSC}, defining the solver type (GMRES, ...); if
\textop{null}, then the PETSc default is used. The `kspparam' is a
solver type specific parameter, currently \textop{null} for
all. Likewise, `pctype' defines the precondition; the possible values
are defined in \textproc{pctypes} of \textproc{PETSC}. As well,
`pcparam' is a preconditioner specific parameter (currently
\textop{null} for all). This operator is matched by
\op{petsc_ksp_destroy}, which discards the `ksp' dictionary and any
associated PETSc memory.

\op{petsc_ksp_tol} sets the divergence/convergence tolerances for the
solver. The parameters are:
\begin{description}
\vspace{-0.5\baselineskip}
\parskip=-0.4\baselineskip
\item[\textproc{K}] solver
\item[\textproc{rtol}] relative tolerance for convergence. 
\item[\textproc{atol}] absolute tolerance for convergence.
\item[\textproc{dtol}] relative tolerance for divergence.
\item[\textproc{maxits}] maximum iterations before divergence is assumed.
\vspace{-0.75\baselineskip}
\end{description}
Convergence is detected if $||r_k||_2 < max(rtol * ||b||_2,\;atol)$,
where $r_k = b - Ax_k$. Divergence is detected if $||r_k||_2 > dtol *
||b||_2$, or if $maxits$ is reached. An error is signaled if
divergence is detected (see \file{dmpetsc.c} for possible divergence
errors, and their mappings from PETSc error codes).

\op{petsc_ksp_solve} actually solves for $x$ in $Ax = b$. On the first
use, $A$ must be given; for later solutions with the same left-hand
side matrix, \textop{null} can be used instead (which will optimize
the solver). If a new $A$ is used, it \emph{must} be a `duplicate' of
the original matrix, as created by \op{petsc_mat_dup}. This guarantees
that the `zero' elements in the same column/rows; the values, of
course, of the non-zero elements need not be the same.

\op{petsc_log_begin} activates PETSc internal logging (see
`PetscLogBegin' in \citet{balay:2004}). To save the current log, use
\op{petsc_log_summary} which takes a directory and a filename to save
the entire log to.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "newbook"
%%% End: 
